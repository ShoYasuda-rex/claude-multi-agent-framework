# /fullstack-trainer

feature-trainer修了者が「DB + 外部API + サーバーレス」を加えた小さなフルスタックプロダクトを1つ作り切ることで、フルスタック開発の型を身体で覚えるための学習スキル。テーマを変えて繰り返し使える。1回あたり2日で完了する想定。

## メタデータ

- description: フルスタック学習。DB・外部API・Workersを加えて開発フローの型を拡張する
- model: opus
- user_invocable: true

## 対象ユーザー

- /feature-trainer を1回以上完走した人
- フロントエンドだけでは物足りなくなった人
- 「データベースって何？」「APIって何？」のレベルからOK
- 次のステップとしてバックエンド技術を体験したい人

## 前提知識の方針

- feature-trainerで学んだことは既知とする（HTML/CSS/JS、GitHub、デプロイ、設計ドキュメントの型）
- **新出の概念（DB、SQL、API、Workers、KV）は初出時に平易な説明を添える**
- feature-trainerと同じく例え話を使う（倉庫・郵便・電話帳など）
- 「feature-trainerでやったのと同じ流れ」と随所で対応関係を示す
- 技術的な操作はAIが実行する前提。ユーザーは「決める人」

## 固定制約（ユーザーには選ばせない）

| 項目 | 固定値 |
|------|--------|
| フロントエンド | スキルがテーマに応じて指定（HTML/CSS/JS、React、Vue等） |
| バックエンド | Cloudflare Workers |
| DB | Cloudflare D1（SQLite互換） |
| キャッシュ | Cloudflare KV |
| 外部API | テーマに応じて1つ（無料APIのみ） |
| ホスティング | Cloudflare Pages + Workers |
| 認証 | レベル1-2: なし / レベル3: 外部認証サービス（Cloudflare Access or Clerk） |
| テーブル数 | 2以内 |
| APIエンドポイント数 | 5以内 |
| 作成期間 | 2日 |

## 完了条件

- GitHubリポジトリが作成されている
- Cloudflare Pages + Workersと連携済み
- D1にテーブルが作成され、CRUD操作が動いている
- 外部APIからデータを取得して表示できている
- 実際にデプロイされて動いている
- 設計ドキュメント（CORE.md / ARCHITECTURE.md）が揃っている

## やってはいけないこと

- スコープ制限を緩める（テーブル2以内・エンドポイント5以内を守る）
- 有料APIを使わせる（無料枠のみ）
- 認証機能を作らせる（固定制約）
- ORMを導入する（生SQLで学ぶ）
- 技術の深い議論に入り込む（本番でやること）
- 完璧を求める（「動いてデプロイできた」が正義）
- 自前で認証ロジックを書かせる（パスワードハッシュ化、セッション管理等）
- Clerkの認証UIをカスタマイズさせる（デフォルトで十分）
- JWTの仕組みを深掘りさせる（本番でやること。今はClerkが返すIDを使うだけ）

## トーン

- feature-trainerと同じ教官トーン。偉そうにしない
- 「feature-trainerでやった型と同じ」と繰り返し安心させる
- 新しい概念（DB、API）は丁寧に。既知の概念（GitHub、デプロイ）はさらっと
- 「なぜ」を必ず説明する
- 褒める時は具体的に（「テーブル設計がシンプルでいい」等）
- 専門用語を使ったら必ず日常語で補足する
- 技術的な操作はAIが実行する前提で説明する

## よくある失敗パターン（各Phaseで警告として使う）

| 失敗 | Phase | 対処 |
|------|-------|------|
| テーブルを増やしたがる | 3, 7 | 「2テーブルで十分。正規化は本番でやる」 |
| APIを複数使いたがる | 1, 3 | 「1つで十分。連携の型を覚えることが目的」 |
| 認証を入れたがる | 3 | 「認証は別の大きなテーマ。今回はデータの型に集中」 |
| SQL文を完璧にしたがる | 7 | 「CRUD（作る・読む・更新・消す）ができれば十分」 |
| エラーハンドリングに凝る | 8 | 「最低限でいい。try-catchで囲んでエラーメッセージ表示」 |
| KVの使いどころがわからない | 6 | 「外部APIの結果をメモしておく場所。毎回聞きに行かなくて済む」 |
| D1とlocalStorageの使い分けに迷う | 7 | 「D1=全員共通のデータ、localStorage=その人だけのデータ」 |
| 自前で認証を実装しようとする | 2 | 「認証は外部に任せる。自分で作ると事故る」 |
| user_idをつけ忘れる | 7 | 「WHERE user_id がないと他人のデータが見える。全クエリに必須」 |
| Clerkの認証画面をカスタマイズしたがる | 8 | 「デフォルトで十分。見た目は本番でやる」 |

---

## 動作フロー

### Phase 0: 前提確認と全体像

feature-trainerの修了を確認し、今回の学びを俯瞰する。

#### 0-1. feature-trainerの振り返り

```
前回の /feature-trainer お疲れさま。

あの時やった流れを覚えている？
CORE → ARCH → 計画 → 実装 → 検証 → デプロイ。

今回もまったく同じ流れでやる。型は変わらない。
変わるのは「使う道具が増える」こと。
```

feature-trainerの修了レベルは聞かない（前提条件を満たしている時点で十分）。すぐに Phase 1 のテーマ提示に進む。

#### 0-2. 今回の新しい道具

```
feature-trainerでは「フロントエンドだけ」で完結した。
データはlocalStorage（ブラウザの中のメモ帳）に保存した。

今回は3つの新しい道具を使う：

【データベース（DB）】データの倉庫。
  localStorageは「自分のブラウザだけ」に保存される。
  DBは「サーバー（インターネット上のコンピュータ）」に保存される。
  つまり、どの端末からアクセスしても同じデータが見える。
  今回は Cloudflare D1 を使う。SQLite互換のDB。

【外部API】他のサービスからデータをもらう仕組み。
  天気情報、書籍情報、レシピ情報...
  自分で全部のデータを作る必要はない。
  他のサービスに「このデータちょうだい」と電話するイメージ。

【Workers】サーバーレス関数。裏方の作業員。
  フロントエンド = お客さんが見る店頭。
  Workers = 裏の厨房。お客さんからは見えない。
  「DBからデータを取ってきて」「APIに聞いてきて」を裏でやる。

図にするとこう：

  ユーザー → フロントエンド → Workers → D1（DB）
                                     → 外部API
                                     → KV（キャッシュ）
```

**【レベル3のみ】**

```
【認証サービス（Clerk）】ログイン機能を丸ごと外注する仕組み。
  自分でパスワード管理やログイン画面を作るのは大変だし危険。
  Clerkに任せれば、サインアップ・ログイン・ログアウトが数行で実装できる。

  あなたがやることは1つだけ：
  「ログインしたユーザーのIDを受け取って、DBのクエリに付ける」

  つまり：
  SELECT * FROM books → SELECT * FROM books WHERE user_id = 'xxx'

  これだけで「自分のデータだけ見える」が実現する。
```

#### 0-3. KVの説明

```
もう1つ、KV（Key-Value Store）という道具がある。

これは「付箋」みたいなもの。
外部APIに毎回電話するのは遅いし、回数制限もある。
だから一度聞いた答えを付箋にメモしておく。
次に同じことを聞かれたら、電話せずに付箋を見る。

これを「キャッシュ」と言う。速度と回数制限の両方を解決する技。
```

#### 0-4. 今回の全体像

```
流れはfeature-trainerと同じ：

0. 前提確認（今ここ）
1. テーマ選択
2. 環境構築 ← Workers + D1 + KV のセットアップが加わる
3. スコープ固定
4. /draft-core
5. /draft-arch ← バックエンド構成が加わる
6. DB設計 ← 新しいPhase。テーブル定義とマイグレーション
7. 計画 → 実装
8. 検証
9. デプロイ
10. 振り返り

「型は同じ、道具が増える」。これだけ。
```

### Phase 1: テーマ選択

レベル別にテーマを3つ提示する。技術スタックと使用するAPIもスキルが指定する。ユーザーが希望するレベルを選ばせる。

**ここで教えること：**

```
今回のテーマには必ず「DB」と「外部API」が含まれる。

feature-trainerでは「フロントだけで完結するもの」だったけど、
今回は「外のサービスと連携するもの」を作る。

技術スタックは前回と同じくこちらで指定する。
APIも指定する。どれも無料で使えるもの。
```

```
【レベル1：DB基礎 + API 1つ】テーブル1つ、基本CRUD
  例：読書記録アプリ（React + D1 + Open Library API）
      → D1にブックリスト保存、Open Library APIで書籍情報を自動取得
  例：天気メモアプリ（Vue + D1 + OpenWeatherMap API）
      → D1にメモ保存、OpenWeatherMapで天気情報を表示
  例：ポケモン図鑑アプリ（HTML/CSS/JS + D1 + PokeAPI）
      → D1にお気に入り保存、PokeAPIでポケモン情報を取得

【レベル2：DB設計 + KV活用】テーブル2つ、リレーション意識
  例：レシピブックマーク（React + D1 + TheMealDB API）
      → D1にレシピ保存（カテゴリ分け）、TheMealDB APIで検索、KVでAPIレスポンスキャッシュ
  例：映画レビュー日記（React + D1 + OMDb API）
      → D1にレビュー保存（映画とレビューのリレーション）、OMDb APIで映画情報取得
  例：国別メモアプリ（Vue + D1 + REST Countries API）
      → D1にメモ保存（国とメモのリレーション）、REST Countries APIで国情報表示

【レベル3：ユーザー管理 + 設計判断】認証・user_idによるデータ分離・集計

  例：パーソナル読書記録（React + D1 + Open Library API + Clerk）
      → Clerk認証でログイン。D1のbooksテーブルにuser_idカラム追加。
        自分の読書記録だけが見える。Open Library APIで書籍情報を自動取得。

  例：マイ家計簿（React + D1 + ExchangeRate-API + Clerk）
      → Clerk認証でログイン。D1の収支データにuser_id紐付け。
        自分の家計だけ表示。月別集計クエリ。KVで為替レートキャッシュ。

  例：個人映画レビュー（Vue + D1 + OMDb API + Clerk）
      → Clerk認証でログイン。レビューデータにuser_id紐付け。
        自分のレビューだけ表示・編集可能。OMDb APIで映画情報取得。
```

上記は例。毎回異なるテーマを生成してもよい。以下を守る：

- D1を必ず使う（テーブル1〜2）
- 無料の外部APIを1つ使う
- Cloudflare Workers でバックエンドを構成する
- 2日で作り切れるサイズ
- 技術スタックとAPIはスキルが決める
- ユーザーに「どれにする？」と選ばせる
- **fullstack-trainerが初回ならレベル1を推奨**（「まず1回完走が最優先」）

**利用可能な無料API一覧（テーマ生成時に参照）：**

| API | 無料枠 | 用途 | APIキー |
|-----|--------|------|---------|
| Open Library | 無制限 | 書籍情報検索 | 不要 |
| PokeAPI | 無制限 | ポケモン情報 | 不要 |
| TheMealDB | 無制限 | レシピ検索 | 不要（テスト用キー `1`） |
| REST Countries | 無制限 | 国情報 | 不要 |
| DiceBear | 無制限 | アバター生成 | 不要 |
| OpenWeatherMap | 1,000回/日 | 天気情報 | 必要（無料登録） |
| OMDb | 1,000回/日 | 映画情報 | 必要（無料登録） |
| ExchangeRate-API | 1,500回/月 | 為替レート | 必要（無料登録） |

APIキーが必要なものは Phase 2 で取得手順を案内する。**APIキー不要のAPIを優先的にテーマに使う**（特にレベル1）。

**ユーザーが「自分でテーマを考えたい」と言った場合**：許可するが、スコープチェックを行う。2日・テーブル2以内・エンドポイント5以内・無料APIの制約に収まるか確認し、収まらなければ縮小を提案する。

### Phase 2: 環境構築

テーマが決まったら、インフラを整える。feature-trainerより手順が多いが、型は同じ。

**ここで教えること：**

```
feature-trainerでもやった「最初に箱を作る」。今回は箱が少し増える。

前回：GitHub + Cloudflare Pages（フロントだけ）
今回：GitHub + Cloudflare Pages + Workers + D1 + KV + GitHub Actions

引っ越しで言うと：
前回は「お店だけ」借りた。
今回は「お店 + 厨房 + 倉庫 + メモ帳」を借りる。
さらに「荷物を送ったら自動で棚に並べてくれる配送業者」も手配する。
でもやることは同じ。先に場所を確保してから中身を作る。
```

手順：

1. **GitHubリポジトリを作成**（feature-trainerと同じ）
2. **Wrangler CLIのセットアップ**
   ```
   Wrangler（ラングラー）は Cloudflare の道具箱。
   Workers、D1、KV を全部これで管理する。
   前回の Cloudflare Pages は画面からポチポチ設定したけど、
   今回はコマンドで設定する。プロの開発者はこっちを使う。
   ```
3. **Workersプロジェクトの初期化**（wrangler init）
4. **D1データベースの作成**（wrangler d1 create）
   ```
   D1データベースを作る。これが「倉庫」。
   中身はまだ空。テーブル（棚）は Phase 7 で作る。
   ```
5. **KVネームスペースの作成**（wrangler kv namespace create）
   ```
   KVを作る。これが「付箋ボード」。
   外部APIの結果をここにメモしておく。
   ```
6. **wrangler.toml の設定**（D1バインディング、KVバインディング）
7. **APIキーの取得と設定**（テーマで使うAPIがキー必要な場合）
   ```
   APIキーとは「身分証明書」。
   無料でも「誰が使っているか」を把握するためにキーが必要なサービスがある。
   登録してキーをもらう。このキーは秘密にする（パスワードと同じ）。
   ```
   - APIキーが必要な場合、取得手順を画面付きで案内する
   - `wrangler secret put API_KEY_NAME` で秘匿設定する
8. **GitHub Actions の設定**（自動デプロイ）
   ```
   GitHub Actions は「自動配送業者」。

   feature-trainerでは GitHub に push したら Cloudflare Pages が自動でデプロイしてくれた。
   今回も同じ体験にする。push するだけで Workers + D1 + KV が全部自動でデプロイされる。

   仕組みはこう：
   1. あなたがコードを GitHub に push する
   2. GitHub Actions が「新しい荷物が来た」と気づく
   3. 自動で wrangler deploy を実行して Cloudflare にデプロイ

   これを CI/CD（継続的デプロイ）と言う。
   プロの開発現場では当たり前の仕組み。手動デプロイは事故のもと。
   ```
   - `.github/workflows/deploy.yml` を作成する
   - ワークフロー内容：
     ```yaml
     name: Deploy
     on:
       push:
         branches: [main]
     jobs:
       deploy:
         runs-on: ubuntu-latest
         steps:
           - uses: actions/checkout@v4
           - uses: cloudflare/wrangler-action@v3
             with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
     ```
   - Cloudflare API Token を取得し、GitHub リポジトリの Secrets に `CLOUDFLARE_API_TOKEN` として登録する
   - D1マイグレーションが必要な場合は deploy ジョブ内に `wrangler d1 migrations apply` ステップを追加する
   ```
   Secrets（シークレット）は GitHub の金庫。
   APIトークンやパスワードなど、秘密にしたい値をここに入れる。
   コードに直接書くと全世界に公開されてしまうので、金庫に入れて鍵で取り出す。
   ```
9. **ローカル開発環境の起動確認**（wrangler dev）
10. **空のプロジェクトをpushして自動デプロイ確認**
    - push → GitHub Actions が起動 → Cloudflare に自動デプロイ、の一連の流れを確認する
    - GitHub Actions タブで「緑のチェック」がつくことを一緒に見る

**【レベル3のみ】**

11. **Clerkアカウント作成とアプリケーション登録**
    ```
    Clerk は「ログインの受付係」。
    アカウントを作って、アプリを登録すると、
    ログイン画面・サインアップ画面が自動で用意される。
    自分で作る必要はない。
    ```
12. **Clerk APIキーの設定**
    - CLERK_PUBLISHABLE_KEY をフロントエンドに設定
    - CLERK_SECRET_KEY を Workers の環境変数に設定（wrangler secret put）
13. **ClerkのMiddleware設定**（Workers側でユーザーIDを取得する仕組み）

**各操作はAIが実行する。** ユーザーには「何が起きているか」を説明しながら進める。


**つまずきやすいポイント（AIが丁寧にナビゲートする）：**

- **APIキーの取得** — 一部の外部APIは「身分証明書（APIキー）」が必要。登録画面をAIが案内する。秘密の値なのでコードに直接書かない。
- **wrangler コマンド** — Cloudflare の道具箱。AIが実行するので覚えなくていい。エラーが出たらAIが対処する。
- **環境変数の設定** — 秘密の値（APIキーなど）を安全に保管する仕組み。手順はAIが案内する。
- **GitHub Actions の設定** — 自動デプロイの仕組み。設定ファイルはAIが作る。

わからなくても手が止まらないようにAIが誘導する。エラーが出ても慌てない。AIに画面を見せれば対処できる。

**ここで教えること：**

```
なぜ最初に全部セットアップするか

前回と同じ理由。「あとでやろう」は事故のもと。
特にD1とKVの設定を後回しにすると、
「ローカルでは動くけどデプロイしたら動かない」が起きやすい。

GitHub Actions も同じ。最後に設定しようとすると
「ローカルでは動くけど自動デプロイが通らない」になる。

今のうちに「箱も配送ルートも全部揃っている」状態にしておく。
push したら自動で公開される。あとは機能を足していくだけ。
```

### Phase 3: スコープ固定

**ここで教えること：**

```
feature-trainerと同じく「やらないこと」を最初に決める。
今回はバックエンドがある分、スコープ爆発のリスクが高い。

「DBがあるから何でもできる」と思いがちだけど、
2日で作り切ることが最優先。制約があるから完成する。
```

選んだテーマに対してスコープを明確にする：

```
このプロダクトの制約：
- 画面は3つ以内
- 主要機能は3つ以内
- テーブルは2つ以内
  → DBの中の「棚」。データの種類ごとに棚を分ける。
    例：「本の棚」と「メモの棚」で2つ。
- APIエンドポイントは5つ以内
  → エンドポイント = Workers が受け付ける窓口の数。
    「データ一覧を返す窓口」「データを保存する窓口」のように。
- 外部APIは1つだけ
- 認証なし（ログイン機能は作らない）
- 2日で完成させる
```

**レベル3の追加制約：**

```
- 認証は外部サービス（Clerk）に任せる。自前で認証ロジックは書かない
- 全テーブルに user_id カラムを追加する
- 全SELECTクエリに WHERE user_id = ? をつける
- 自前でのパスワード管理・ハッシュ化は禁止（外部に任せる）
- 認証周りの画面（サインアップ・ログイン）はClerkのコンポーネントをそのまま使う
```

### Phase 4: /draft-core 体験

```
設計フェーズに入る。feature-trainerと同じ流れ。

まず /draft-core。「何を作るか」を決める。
技術の話はしない。「誰の、何の課題を、どう解決するか」だけ。

前回やったから流れはわかるはず。同じ型。
```

**実行**: /draft-core を起動する。起動時に以下の制約をコンテキストに含める：

```
【fullstack-trainer モード】
フルスタック学習中。対象は2日で作る小さなプロダクト。
テーマ: [選択したテーマ]
技術: [フロントエンド] + Cloudflare Workers + D1 + KV
外部API: [選択したAPI]
制約: テーブル2以内、エンドポイント5以内、認証なし
ヒアリングは3問以内。出力は簡潔に。
```

### Phase 5: /draft-arch 体験

```
次は /draft-arch。「どう作るか」を技術的に決める。

feature-trainerではフロントエンドだけだった。
今回は「バックエンド構成」が加わる。

ARCHITECTURE.md に書くことが増える：
1. ディレクトリ構成（前回と同じ + Workers用フォルダ）
2. コンポーネント設計（前回と同じ）
3. Workers のエンドポイント設計
   → 「この窓口はこのデータを返す」の一覧
4. D1 のテーブル設計
   → 「この棚にはこの情報を入れる」の設計
5. KV のキャッシュ設計
   → 「この付箋にはこの情報をメモする。何時間で捨てる」
6. 外部API連携設計
   → 「このAPIに何を聞いて、結果をどう使うか」
```

**実行**: /draft-arch を起動。fullstack-trainerモードの制約を渡す。

**注意**: ORMは使わない。生SQLでD1を操作する設計にする（学習目的）。

### Phase 6: DB設計

**feature-trainerにはなかった新しいPhase。**

**ここで教えること：**

```
ここが今回の一番の山場。「テーブル設計」をやる。

テーブルとは、Excelの表みたいなもの。
- 列（カラム）= 項目名（「タイトル」「著者」「登録日」）
- 行（レコード）= 1件分のデータ

例えば読書記録アプリなら：

books テーブル:
| id | title        | author    | status | created_at |
|----|-------------|-----------|--------|------------|
| 1  | 坊っちゃん    | 夏目漱石   | 読了    | 2024-01-15 |
| 2  | 人間失格     | 太宰治     | 読書中  | 2024-01-20 |

この「枠組み」を最初に決める。
あとからカラムを追加するのは面倒なので、先に設計する。
```

**【レベル3のみ】**

```
テーブルにuser_idカラムを追加する。これが「誰のデータか」を区別する鍵。

例：
CREATE TABLE books (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  user_id TEXT NOT NULL,  ← これが追加
  title TEXT NOT NULL,
  author TEXT,
  status TEXT DEFAULT '未読',
  created_at TEXT DEFAULT (datetime('now'))
);

全SELECTに WHERE user_id = ? をつける：
SELECT * FROM books WHERE user_id = ?;

全INSERTに user_id を含める：
INSERT INTO books (user_id, title, author) VALUES (?, ?, ?);

これだけ。DBの観点では「カラム1つ追加してWHERE句に入れる」だけ。
認証サービスが返すユーザーIDをそのまま使う。
```

#### 7-1. SQLの基礎（最小限）

```
テーブルを操作するのが SQL（エスキューエル）という言語。
今回覚えるのは4つだけ：

【CREATE TABLE】テーブル（棚）を作る
【INSERT】データを入れる
【SELECT】データを取り出す
【DELETE】データを消す

UPDATE（更新）も使うかもしれないが、基本はこの4つ。
AIがSQL文を書くので、「こういう意味か」とわかればOK。
```

#### 7-2. テーブル定義

ARCHITECTURE.md のテーブル設計をもとに、実際のCREATE TABLE文を作成する。

```
これが「マイグレーション」。
テーブルの設計図をSQLで書いて、D1に実行させる。
「この棚をこの形で作ってください」と指示する。
```

**実行**: マイグレーションファイルを作成し、`wrangler d1 execute` でテーブルを作成する。ローカルD1で動作確認する。

#### 7-3. 動作確認

テストデータを INSERT して SELECT で取り出す。ユーザーに見せて「DBが動いている」ことを実感させる。

```
今、D1にデータが入って、取り出せた。
これがデータベースの基本。入れる・出す・消す。

localStorageとの違いは：
- localStorage → そのブラウザだけ。端末が変わると消える。
- D1 → サーバー上。どこからアクセスしても同じデータ。
```

### Phase 7: 実装

```
設計とDB準備が終わった。あとはfeature-trainerと同じ流れ。

.tpi で並列実装する。
型は同じ。道具が増えただけ。
```

**実行**:
1. .tpi で並列実装を実行する

実装時の注意点（.tpi に渡すコンテキスト）：
- Workers のエンドポイントは ARCHITECTURE.md の設計通りに
- D1操作は生SQL（ORMなし）
- 外部API呼び出しは Workers 経由（フロントから直接呼ばない）
- KVキャッシュは ARCHITECTURE.md のキャッシュ設計通りに
- APIキーは環境変数（`env.API_KEY_NAME`）から取得。ハードコーディング厳禁
- エラーハンドリングは最低限（try-catch + ユーザーへのメッセージ表示）

### Phase 8: 検証

```
feature-trainerと同じ3段階チェック。

.cc → コードの品質（Workers側のコードも含む）
.vc → 画面の動作確認（API連携が動いているか、データが保存されるか）

今回は「DBにデータが正しく保存されているか」
「外部APIからデータが取れているか」も確認項目に入る。
```


### Phase 9: デプロイ

```
検証を通過したらデプロイ。

feature-trainerと同じ。push するだけ。

Phase 2 で GitHub Actions を設定済みだから、
push したら自動で Workers + D1 + KV が全部デプロイされる。
手動で何かする必要はない。

前回と同じ体験：push → 自動デプロイ → URL で確認。
```

**実行**:
1. /deploy で GitHub push
2. GitHub Actions タブで自動デプロイの進行を確認（緑のチェックがつくまで待つ）
3. 本番URLで動作確認

**デプロイ後の確認ポイント：**
- フロントエンドが表示されるか
- Workers経由でD1のデータが取得できるか
- 外部APIからデータが取れるか
- KVキャッシュが効いているか（2回目のアクセスが速いか）

**ここで教えること：**

```
Phase 2 で GitHub Actions を先に設定しておいた意味がここで効く。

push しただけで全部デプロイされた。
フロントもバックエンドもDBも、全部自動。

これが CI/CD の力。
「push = デプロイ」のパイプラインを最初に作っておけば、
あとは機能を作ることだけに集中できる。

本番の開発でも同じ。環境構築と自動デプロイは最初にやる。
```

**デプロイ後、実際のURLをブラウザで開いて一緒に確認する。** 「前回はフロントだけだったけど、今回はDBもAPIも動いている」と伝える。

### Phase 10: 振り返り

```
完了！フルスタックのプロダクトを、同じフレームワークの型で作り上げた。

■ 今回の流れ（feature-trainerとの対比）
0. 前提確認 ← 前回はオリエンテーション
1. テーマ選択 ← 同じ型
2. 環境構築 ← Workers + D1 + KV + GitHub Actions が追加
3. スコープ固定 ← 同じ型（DB/APIの制約が追加）
4. /draft-core ← 同じ型
5. /draft-arch ← バックエンド構成が追加
6. DB設計 ← 新しいPhase
7. 実装 ← 同じ型
8. 検証 ← 同じ型
9. デプロイ ← push だけ（GitHub Actions で自動デプロイ）
10. 振り返り ← 今ここ

■ 気づいてほしいこと
- 型は変わらなかった。Why → How → What → Code の流れは同じ
- 道具が増えても、やることの順番は同じ
- 新しいのは「DB設計」だけ。それ以外は拡張しただけ

■ 今回学んだ技術（振り返り）
- データベース（D1）→ サーバー上のデータ倉庫。どこからでもアクセス可
- SQL → DBを操作する言語。CRUD（Create, Read, Update, Delete）
- マイグレーション → テーブルの設計図をSQLで書いて実行すること
- 外部API → 他のサービスからデータをもらう仕組み
- APIキー → APIを使うための身分証明書。秘密にする
- Workers → サーバーレス関数。裏方の作業員
- KV → 付箋ボード。APIの結果をメモして高速化
- エンドポイント → Workers が受け付ける窓口
- 環境変数 → 秘密の設定値。コードに直接書かない
- GitHub Actions → 自動配送業者。push したら自動でデプロイ
- CI/CD → 継続的デプロイ。手動デプロイを排除する仕組み
- Secrets → GitHub の金庫。APIトークンなど秘密の値を安全に保管

【レベル3のみ】
- 認証 → 「この人は誰か」を確認する仕組み
- 外部認証サービス（Clerk）→ ログイン機能の外注先。自前で作らない
- user_id → DBのレコードに「持ち主」をつけるカラム
- WHERE user_id = ? → 「自分のデータだけ取り出す」クエリ
- マルチテナント → 1つのアプリを複数ユーザーが使う設計。user_idで分離

これらも「覚えなきゃ」と思わなくていい。
2回目、3回目とやるうちに自然と身につく。

■ 次にやること
- 別のテーマで /fullstack-trainer をもう1回やる（レベルを上げて）
- 慣れたら /draft-core から自分のフルスタックプロダクトを作ってみる
- feature-trainerで作ったプロダクトにDB + APIを足してみるのもいい
```

## 既存スキルとの連携

- /draft-core, /draft-arch を実際に呼び出す
- 呼び出し時に「fullstack-trainerモード」の制約情報をコンテキストに含める
- 各スキルのヒアリングは通常より簡潔にする指示を渡す（3問以内目安）
- 出力フォーマットは既存スキルのものをそのまま使う
- /draft-arch では Workers + D1 + KV の構成を含める指示を追加する

## このスキルの本質

このスキルの価値は「フルスタック技術を覚える」ことではなく、「型はスケールする」と実感すること。

feature-trainerで学んだ型（CORE → ARCH → 実装 → 検証 → デプロイ）は、フロントエンドだけでなくフルスタック開発でもそのまま使える。道具が増えても、思考の順番は変わらない。

成果物のプロダクト自体は小さい。でも：
- なぜ DB 設計を ARCH の後・実装の前にやるのか
- なぜ外部APIを Workers 経由で呼ぶのか（フロントから直接呼ばない理由）
- なぜ APIキーを環境変数にするのか
- なぜ KV でキャッシュするのか
- D1 と localStorage はどう使い分けるのか
- なぜ認証を自前で作らないのか（セキュリティリスクと開発コスト）
- なぜ user_id を全テーブルに入れるのか（マルチテナントの基本）
- 「WHERE user_id = ?」が全ての起点であること

これが身体で理解できていれば、本番のフルスタック開発でも同じ型が使える。
