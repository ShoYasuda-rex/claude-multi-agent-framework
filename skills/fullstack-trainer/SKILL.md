# /fullstack-trainer

feature-trainer修了者が「DB + 外部API + サーバーレス」を加えた小さなフルスタックプロダクトを1つ作り切ることで、フルスタック開発の型を身体で覚えるための学習スキル。テーマを変えて繰り返し使える。1回あたり2日で完了する想定。

## メタデータ

- description: フルスタック学習。DB・外部API・Workersを加えて開発フローの型を拡張する
- model: opus
- user_invocable: true

## 対象ユーザー

- /feature-trainer を1回以上完走した人
- フロントエンドだけでは物足りなくなった人
- 「データベースって何？」「APIって何？」のレベルからOK
- 次のステップとしてバックエンド技術を体験したい人

## 前提知識の方針

- feature-trainerで学んだことは既知とする（HTML/CSS/JS、GitHub、デプロイ、設計ドキュメントの型）
- **新出の概念（DB、SQL、API、Workers、KV）は初出時に平易な説明を添える**
- feature-trainerと同じく例え話を使う（倉庫・郵便・電話帳など）
- 「feature-trainerでやったのと同じ流れ」と随所で対応関係を示す
- 技術的な操作はAIが実行する前提。ユーザーは「決める人」
- **既知のスキル（/draft、/verify、/deploy等）を使う場面でも、今回の文脈での役割を毎回説明する。「前回やったから省略」はしない**

## 固定制約（ユーザーには選ばせない）

| 項目 | 固定値 |
|------|--------|
| フロントエンド | スキルがテーマに応じて指定（HTML/CSS/JS、React、Vue等） |
| バックエンド | Cloudflare Workers |
| DB | Cloudflare D1（SQLite互換） |
| キャッシュ | Cloudflare KV |
| 外部API | テーマに応じて1つ（無料APIのみ） |
| ホスティング | Cloudflare Pages + Workers |
| 認証 | レベル1-2: なし / レベル3: 外部認証サービス（Cloudflare Access or Clerk） |
| テーブル数 | 2以内 |
| APIエンドポイント数 | 5以内 |
| 作成期間 | 2日 |

## 完了条件

- GitHubリポジトリが作成されている
- Cloudflare Pages + Workersと連携済み
- D1にテーブルが作成され、CRUD操作が動いている
- 外部APIからデータを取得して表示できている
- 実際にデプロイされて動いている
- 設計ドキュメント（CORE.md / ARCHITECTURE.md）が揃っている

## やってはいけないこと

- スコープ制限を緩める（テーブル2以内・エンドポイント5以内を守る）
- 有料APIを使わせる（無料枠のみ）
- 認証機能を作らせる（固定制約）
- ORMを導入する（生SQLで学ぶ）
- 技術の深い議論に入り込む（本番でやること）
- 完璧を求める（「動いてデプロイできた」が正義）
- 自前で認証ロジックを書かせる（パスワードハッシュ化、セッション管理等）
- Clerkの認証UIをカスタマイズさせる（デフォルトで十分）
- JWTの仕組みを深掘りさせる（本番でやること。今はClerkが返すIDを使うだけ）
- **既知のスキル（/draft、/verify、/deploy等）の解説を省略する（feature-trainerでやったからと言って飛ばさない）**

## トーン

- feature-trainerと同じ教官トーン。偉そうにしない
- 「feature-trainerでやった型と同じ」と繰り返し安心させる
- 新しい概念（DB、API）は丁寧に。既知の概念（GitHub、デプロイ）はさらっと
- 「なぜ」を必ず説明する
- 褒める時は具体的に（「テーブル設計がシンプルでいい」等）
- 専門用語を使ったら必ず日常語で補足する
- 技術的な操作はAIが実行する前提で説明する

## よくある失敗パターン（各Phaseで警告として使う）

| 失敗 | Phase | 対処 |
|------|-------|------|
| テーブルを増やしたがる | 3, 5 | 「2テーブルで十分。正規化は本番でやる」 |
| APIを複数使いたがる | 1, 3 | 「1つで十分。連携の型を覚えることが目的」 |
| 認証を入れたがる | 3 | 「認証は別の大きなテーマ。今回はデータの型に集中」 |
| SQL文を完璧にしたがる | 5 | 「CRUD（作る・読む・更新・消す）ができれば十分」 |
| エラーハンドリングに凝る | 6 | 「最低限でいい。try-catchで囲んでエラーメッセージ表示」 |
| KVの使いどころがわからない | 4 | 「外部APIの結果をメモしておく場所。毎回聞きに行かなくて済む」 |
| D1とlocalStorageの使い分けに迷う | 5 | 「D1=全員共通のデータ、localStorage=その人だけのデータ」 |
| 自前で認証を実装しようとする | 2 | 「認証は外部に任せる。自分で作ると事故る」 |
| user_idをつけ忘れる | 5 | 「WHERE user_id がないと他人のデータが見える。全クエリに必須」 |
| Clerkの認証画面をカスタマイズしたがる | 6 | 「デフォルトで十分。見た目は本番でやる」 |
| 検証を飛ばしたがる | 7 | 「動くと正しいは違う。DBにデータが正しく入っているかは見た目じゃわからない」 |
| デプロイを後回しにする | 2 | 「最後にやると『ローカルでは動くのに本番で動かない』事故が起きる」 |

---

## 動作フロー

### Phase 0: 前提確認と全体像

feature-trainerの修了を確認し、今回の学びを俯瞰する。

#### 0-1. feature-trainerの振り返り

```
前回の /feature-trainer お疲れさま。

あの時やった流れを覚えている？
CORE → ARCH → 計画 → 実装 → 検証 → デプロイ。

今回もまったく同じ流れでやる。型は変わらない。
変わるのは「使う道具が増える」こと。
```

feature-trainerの修了レベルは聞かない（前提条件を満たしている時点で十分）。すぐに Phase 1 のテーマ提示に進む。

#### 0-2. 今回の新しい道具

```
feature-trainerでは「フロントエンドだけ」で完結した。
データはlocalStorage（ブラウザの中のメモ帳）に保存した。

今回は3つの新しい道具を使う：

【データベース（DB）】データの倉庫。
  localStorageは「自分のブラウザだけ」に保存される。
  DBは「サーバー（インターネット上のコンピュータ）」に保存される。
  つまり、どの端末からアクセスしても同じデータが見える。
  今回は Cloudflare D1 を使う。SQLite互換のDB。

【外部API】他のサービスからデータをもらう仕組み。
  天気情報、書籍情報、レシピ情報...
  自分で全部のデータを作る必要はない。
  他のサービスに「このデータちょうだい」と電話するイメージ。

【Workers】サーバーレス関数。裏方の作業員。
  フロントエンド = お客さんが見る店頭。
  Workers = 裏の厨房。お客さんからは見えない。
  「DBからデータを取ってきて」「APIに聞いてきて」を裏でやる。

図にするとこう：

  ユーザー → フロントエンド → Workers → D1（DB）
                                     → 外部API
                                     → KV（キャッシュ）
```

**【レベル3のみ】**

```
【認証サービス（Clerk）】ログイン機能を丸ごと外注する仕組み。
  自分でパスワード管理やログイン画面を作るのは大変だし危険。
  Clerkに任せれば、サインアップ・ログイン・ログアウトが数行で実装できる。

  あなたがやることは1つだけ：
  「ログインしたユーザーのIDを受け取って、DBのクエリに付ける」

  つまり：
  SELECT * FROM books → SELECT * FROM books WHERE user_id = 'xxx'

  これだけで「自分のデータだけ見える」が実現する。
```

#### 0-3. KVの説明

```
もう1つ、KV（Key-Value Store）という道具がある。

これは「付箋」みたいなもの。
外部APIに毎回電話するのは遅いし、回数制限もある。
だから一度聞いた答えを付箋にメモしておく。
次に同じことを聞かれたら、電話せずに付箋を見る。

これを「キャッシュ」と言う。速度と回数制限の両方を解決する技。
```

#### 0-4. 今回の全体像

```
流れはfeature-trainerと同じ：

0. 前提確認（今ここ）
1. テーマ選択
2. 環境構築 ← Workers + D1 + KV のセットアップが加わる
3. スコープ固定
4. /draft ← 「何を作るか」＋「どう作るか」を一気通貫で設計
5. DB設計 ← 新しいPhase。テーブル定義とマイグレーション
6. 実装指示 → 並列実装
7. /verify ← 検証。DBやAPIの動作確認も含む
8. /deploy ← デプロイ。GitHub Actionsで自動化
9. 振り返り

「型は同じ、道具が増える」。これだけ。
```

#### 0-5. つまずいた時の案内

```
途中でわからないこと・動かないことがあったら、遠慮なく聞いて。
エラー画面のスクリーンショットや、何をやって何が起きたかを教えてくれれば対処できる。
「何がわからないかわからない」でもOK。状況を一緒に見る。

今回は新しい道具が増える分、エラーも増える可能性がある。
エラーが出るのは普通のこと。AIが対処するので、慌てなくて大丈夫。
```

### Phase 1: テーマ選択

レベル別にテーマを3つ提示する。技術スタックと使用するAPIもスキルが指定する。ユーザーが希望するレベルを選ばせる。

**ここで教えること：**

```
今回のテーマには必ず「DB」と「外部API」が含まれる。

feature-trainerでは「フロントだけで完結するもの」だったけど、
今回は「外のサービスと連携するもの」を作る。

技術スタックは前回と同じくこちらで指定する。
APIも指定する。どれも無料で使えるもの。

テーマを選ぶときのポイント：
- 「自分が使いたい」と思えるものを選ぶと、モチベーションが続く
- 初回ならレベル1がおすすめ。まず完走することが最優先
- 「全部のレベルを順番にやる」のが理想。急がなくていい
```

```
【レベル1：DB基礎 + API 1つ】テーブル1つ、基本CRUD
  例：読書記録アプリ（React + D1 + Open Library API）
      → D1にブックリスト保存、Open Library APIで書籍情報を自動取得
  例：天気メモアプリ（Vue + D1 + OpenWeatherMap API）
      → D1にメモ保存、OpenWeatherMapで天気情報を表示
  例：ポケモン図鑑アプリ（HTML/CSS/JS + D1 + PokeAPI）
      → D1にお気に入り保存、PokeAPIでポケモン情報を取得

【レベル2：DB設計 + KV活用】テーブル2つ、リレーション意識
  例：レシピブックマーク（React + D1 + TheMealDB API）
      → D1にレシピ保存（カテゴリ分け）、TheMealDB APIで検索、KVでAPIレスポンスキャッシュ
  例：映画レビュー日記（React + D1 + OMDb API）
      → D1にレビュー保存（映画とレビューのリレーション）、OMDb APIで映画情報取得
  例：国別メモアプリ（Vue + D1 + REST Countries API）
      → D1にメモ保存（国とメモのリレーション）、REST Countries APIで国情報表示

【レベル3：ユーザー管理 + 設計判断】認証・user_idによるデータ分離・集計

  例：パーソナル読書記録（React + D1 + Open Library API + Clerk）
      → Clerk認証でログイン。D1のbooksテーブルにuser_idカラム追加。
        自分の読書記録だけが見える。Open Library APIで書籍情報を自動取得。

  例：マイ家計簿（React + D1 + ExchangeRate-API + Clerk）
      → Clerk認証でログイン。D1の収支データにuser_id紐付け。
        自分の家計だけ表示。月別集計クエリ。KVで為替レートキャッシュ。

  例：個人映画レビュー（Vue + D1 + OMDb API + Clerk）
      → Clerk認証でログイン。レビューデータにuser_id紐付け。
        自分のレビューだけ表示・編集可能。OMDb APIで映画情報取得。
```

上記は例。毎回異なるテーマを生成してもよい。以下を守る：

- D1を必ず使う（テーブル1〜2）
- 無料の外部APIを1つ使う
- Cloudflare Workers でバックエンドを構成する
- 2日で作り切れるサイズ
- 技術スタックとAPIはスキルが決める
- ユーザーに「どれにする？」と選ばせる
- **fullstack-trainerが初回ならレベル1を推奨**（「まず1回完走が最優先」）

**利用可能な無料API一覧（テーマ生成時に参照）：**

| API | 無料枠 | 用途 | APIキー |
|-----|--------|------|---------|
| Open Library | 無制限 | 書籍情報検索 | 不要 |
| PokeAPI | 無制限 | ポケモン情報 | 不要 |
| TheMealDB | 無制限 | レシピ検索 | 不要（テスト用キー `1`） |
| REST Countries | 無制限 | 国情報 | 不要 |
| DiceBear | 無制限 | アバター生成 | 不要 |
| OpenWeatherMap | 1,000回/日 | 天気情報 | 必要（無料登録） |
| OMDb | 1,000回/日 | 映画情報 | 必要（無料登録） |
| ExchangeRate-API | 1,500回/月 | 為替レート | 必要（無料登録） |

APIキーが必要なものは Phase 2 で取得手順を案内する。**APIキー不要のAPIを優先的にテーマに使う**（特にレベル1）。

**ユーザーが「自分でテーマを考えたい」と言った場合**：許可するが、スコープチェックを行う。2日・テーブル2以内・エンドポイント5以内・無料APIの制約に収まるか確認し、収まらなければ縮小を提案する。

### Phase 2: 環境構築

テーマが決まったら、インフラを整える。feature-trainerより手順が多いが、型は同じ。

**ここで教えること：**

```
feature-trainerでもやった「最初に箱を作る」。今回は箱が少し増える。

前回：GitHub + Cloudflare Pages（フロントだけ）
今回：GitHub + Cloudflare Pages + Workers + D1 + KV + GitHub Actions

引っ越しで言うと：
前回は「お店だけ」借りた。
今回は「お店 + 厨房 + 倉庫 + メモ帳」を借りる。
さらに「荷物を送ったら自動で棚に並べてくれる配送業者」も手配する。
でもやることは同じ。先に場所を確保してから中身を作る。
```

手順：

1. **GitHubリポジトリを作成**（feature-trainerと同じ）
   ```
   前回もやった「コードの保管庫を借りる」。同じ手順。
   ```
2. **Wrangler CLIのセットアップ**
   ```
   Wrangler（ラングラー）は Cloudflare の道具箱。
   Workers、D1、KV を全部これで管理する。
   前回の Cloudflare Pages は画面からポチポチ設定したけど、
   今回はコマンドで設定する。プロの開発者はこっちを使う。

   あなたは何もしなくていい。AIがコマンドを実行する。
   ```
3. **Workersプロジェクトの初期化**（wrangler init）
4. **D1データベースの作成**（wrangler d1 create）
   ```
   D1データベースを作る。これが「倉庫」。
   中身はまだ空。テーブル（棚）は Phase 5 で作る。
   ```
5. **KVネームスペースの作成**（wrangler kv namespace create）
   ```
   KVを作る。これが「付箋ボード」。
   外部APIの結果をここにメモしておく。
   ```
6. **wrangler.toml の設定**（D1バインディング、KVバインディング）
   ```
   wrangler.toml は「設定ファイル」。
   「このWorkersはD1のこの倉庫を使う」「KVのこの付箋ボードを使う」
   という接続情報を書いておく場所。
   住所録みたいなもの。AIが書く。
   ```
7. **APIキーの取得と設定**（テーマで使うAPIがキー必要な場合）
   ```
   APIキーとは「身分証明書」。
   無料でも「誰が使っているか」を把握するためにキーが必要なサービスがある。
   登録してキーをもらう。このキーは秘密にする（パスワードと同じ）。

   なぜ秘密にする？
   キーが漏れると、他の人があなたのキーで大量にAPIを呼び出せてしまう。
   すると無料枠を使い切ったり、悪用されたりする。
   だからコードに直接書かない。「環境変数」という安全な場所に置く。
   ```
   - APIキーが必要な場合、取得手順を画面付きで案内する
   - `wrangler secret put API_KEY_NAME` で秘匿設定する
8. **GitHub Actions の設定**（自動デプロイ）
   ```
   GitHub Actions は「自動配送業者」。

   feature-trainerでは GitHub に push したら Cloudflare Pages が自動でデプロイしてくれた。
   今回も同じ体験にする。push するだけで Workers + D1 + KV が全部自動でデプロイされる。

   仕組みはこう：
   1. あなたがコードを GitHub に push する
   2. GitHub Actions が「新しい荷物が来た」と気づく
   3. 自動で wrangler deploy を実行して Cloudflare にデプロイ

   これを CI/CD（継続的デプロイ）と言う。
   プロの開発現場では当たり前の仕組み。手動デプロイは事故のもと。

   CI = Continuous Integration（継続的統合）: コードが壊れていないか自動チェック
   CD = Continuous Deployment（継続的デプロイ）: チェックが通ったら自動で公開

   難しそうに聞こえるけど、やることは「設定ファイルを1つ置く」だけ。
   AIが作る。
   ```
   - `.github/workflows/deploy.yml` を作成する
   - ワークフロー内容：
     ```yaml
     name: Deploy
     on:
       push:
         branches: [main]
     jobs:
       deploy:
         runs-on: ubuntu-latest
         steps:
           - uses: actions/checkout@v4
           - uses: cloudflare/wrangler-action@v3
             with:
               apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
     ```
   - Cloudflare API Token を取得し、GitHub リポジトリの Secrets に `CLOUDFLARE_API_TOKEN` として登録する
   - D1マイグレーションが必要な場合は deploy ジョブ内に `wrangler d1 migrations apply` ステップを追加する
   ```
   Secrets（シークレット）は GitHub の金庫。
   APIトークンやパスワードなど、秘密にしたい値をここに入れる。
   コードに直接書くと全世界に公開されてしまうので、金庫に入れて鍵で取り出す。

   金庫に入れた値は、GitHub Actions が自動で取り出して使う。
   あなたが毎回入力する必要はない。
   ```
9. **ローカル開発環境の起動確認**（wrangler dev）
   ```
   「ローカル」= 自分のパソコンの中。feature-trainerでもやった。
   wrangler dev でWorkersをローカルで動かせる。
   D1もKVもローカルで動く。インターネットに繋がなくても開発できる。
   ```
10. **空のプロジェクトをpushして自動デプロイ確認**
    - push → GitHub Actions が起動 → Cloudflare に自動デプロイ、の一連の流れを確認する
    - GitHub Actions タブで「緑のチェック」がつくことを一緒に見る
    ```
    ここで一連の流れを確認する：
    1. コードをGitHubに送る（push）
    2. GitHub Actions が自動で起動する
    3. Cloudflare に自動でデプロイされる

    緑のチェックマーク ✅ が出ればOK。
    赤い × が出たらエラー。AIが原因を調べて直す。

    この「push したら自動で公開される」パイプラインが、
    Phase 8 のデプロイで活きてくる。
    ```

**【レベル3のみ】**

11. **Clerkアカウント作成とアプリケーション登録**
    ```
    Clerk は「ログインの受付係」。
    アカウントを作って、アプリを登録すると、
    ログイン画面・サインアップ画面が自動で用意される。
    自分で作る必要はない。

    なぜ自分で作らない？
    ログイン機能は「セキュリティの塊」。
    パスワードの暗号化、セッション管理、ブルートフォース対策...
    自分で作ると穴だらけになる。プロでもミスる。
    だから専門家（Clerk）に任せる。これが現代の常識。
    ```
12. **Clerk APIキーの設定**
    - CLERK_PUBLISHABLE_KEY をフロントエンドに設定
    - CLERK_SECRET_KEY を Workers の環境変数に設定（wrangler secret put）
    ```
    Clerkには2つの鍵がある：
    - PUBLISHABLE_KEY: お店の看板。見えてもいい。フロントエンドに置く
    - SECRET_KEY: 裏口の鍵。絶対に見せてはダメ。Workersの環境変数に置く

    なぜ2つ？
    フロントエンドのコードはブラウザに送られるから、誰でも見れる。
    だからフロントには「見えてもいい鍵」だけ置く。
    本当に大事な操作は裏方（Workers）でやる。
    ```
13. **ClerkのMiddleware設定**（Workers側でユーザーIDを取得する仕組み）

**各操作はAIが実行する。** ユーザーには「何が起きているか」を説明しながら進める。


**つまずきやすいポイント（AIが丁寧にナビゲートする）：**

- **APIキーの取得** — 一部の外部APIは「身分証明書（APIキー）」が必要。登録画面をAIが案内する。秘密の値なのでコードに直接書かない
- **wrangler コマンド** — Cloudflare の道具箱。AIが実行するので覚えなくていい。エラーが出たらAIが対処する
- **環境変数の設定** — 秘密の値（APIキーなど）を安全に保管する仕組み。手順はAIが案内する
- **GitHub Actions の設定** — 自動デプロイの仕組み。設定ファイルはAIが作る
- **「エラーが出た！」** — エラーが出るのは普通。AIに画面を見せれば対処できる。慌てなくて大丈夫

わからなくても手が止まらないようにAIが誘導する。

**ここで教えること：**

```
なぜ最初に全部セットアップするか

前回と同じ理由。「あとでやろう」は事故のもと。
特にD1とKVの設定を後回しにすると、
「ローカルでは動くけどデプロイしたら動かない」が起きやすい。

GitHub Actions も同じ。最後に設定しようとすると
「ローカルでは動くけど自動デプロイが通らない」になる。

今のうちに「箱も配送ルートも全部揃っている」状態にしておく。
push したら自動で公開される。あとは機能を足していくだけ。

feature-trainerでも「環境構築は先にやる」と学んだ。
同じ原則。道具が増えても原則は変わらない。
```

### Phase 3: スコープ固定

**ここで教えること：**

```
feature-trainerでもやった「やらないこと」を最初に決める。
「スコープ」= やる範囲。feature-trainerで学んだ概念。

今回はバックエンドがある分、スコープ爆発のリスクが高い。

「DBがあるから何でもできる」と思いがちだけど、
2日で作り切ることが最優先。制約があるから完成する。

feature-trainerで学んだこと：
「完成した小さなもの」は「未完成の大きなもの」より価値がある。
同じ原則をここでも使う。
```

選んだテーマに対してスコープを明確にする：

```
このプロダクトの制約：
- 画面は3つ以内
- 主要機能は3つ以内
- テーブルは2つ以内
  → DBの中の「棚」。データの種類ごとに棚を分ける。
    例：「本の棚」と「メモの棚」で2つ。
- APIエンドポイントは5つ以内
  → エンドポイント = Workers が受け付ける窓口の数。
    「データ一覧を返す窓口」「データを保存する窓口」のように。
    レストランで言えば「注文窓口」「会計窓口」「問い合わせ窓口」。
- 外部APIは1つだけ
- 認証なし（ログイン機能は作らない）
- 2日で完成させる
```

**レベル3の追加制約：**

```
- 認証は外部サービス（Clerk）に任せる。自前で認証ロジックは書かない
- 全テーブルに user_id カラムを追加する
- 全SELECTクエリに WHERE user_id = ? をつける
- 自前でのパスワード管理・ハッシュ化は禁止（外部に任せる）
- 認証周りの画面（サインアップ・ログイン）はClerkのコンポーネントをそのまま使う
```

### Phase 4: /draft 体験

**ここで教えること：**

```
設計フェーズに入る。feature-trainerと同じ流れ。

/draft は「何を作るか」と「どう作るか」を一気通貫で決めるスキル。

前半はCORE.md。覚えている？
「何を作るか」を決める。技術の話は一切しない。
「誰の、何の課題を、どう解決するか」だけを整理する。

CORE.mdは「メニューを決める」パート。
料理を始める前に「今日は何を作るか」を決める。
これがないと、AIも「何を作ればいいかわからない」状態になる。

前回と違うのは、今回のプロダクトには
「DBにデータを保存する」「外部APIからデータを取る」要素がある点。
でも前半のCORE.mdでは技術の話をしない。
「ユーザーが本の記録をつけたい」「レシピを検索して保存したい」
のように、ユーザーの言葉で書く。

後半はARCHITECTURE.md。「どう作るか」を技術的に決める。

feature-trainerでは「メニューを決めた後にレシピを書く」と説明した。
今回も同じ。CORE.md（メニュー）ができたら、次はARCHITECTURE.md（レシピ）。

feature-trainerではフロントエンドだけだった。
今回は「バックエンド構成」が加わる。

ARCHITECTURE.md に書くことが増える：
1. ディレクトリ構成（前回と同じ + Workers用フォルダ）
2. コンポーネント設計（前回と同じ）
3. Workers のエンドポイント設計 ← 新しい
4. D1 のテーブル設計 ← 新しい
5. KV のキャッシュ設計 ← 新しい
6. 外部API連携設計 ← 新しい

増えたのは3〜6の部分。でもAIが主導するから、
「こういう構成でいい？」と聞かれたら「OK」か「ここを変えたい」と答えればいい。

できあがるもの:
- docs/CORE.md（プロダクトの設計図の「Why」の部分）
- docs/ARCHITECTURE.md（プロダクトの設計図の「How」の部分）
```

**よくある失敗：**
- 技術の話を始めてしまう → 「前半は作り方の話はしない。まず何を作るか決めよう」
- 「D1にデータを保存して...」と書く → 「技術は後半のARCH設計で。ここは『ユーザーの記録を残せる』でいい」
- 「エンドポイント増やしたい」→ 「5つ以内。窓口が多いと管理が大変になる」
- コードの書き方の話になる → 「コードレベルの話は実装時に。今は構造の大枠だけ」

**実行**: /draft を起動。fullstack-trainerモードの制約を渡す:

```
【fullstack-trainer モード】
フルスタック学習中。対象は2日で作る小さなプロダクト。
テーマ: [選択したテーマ]
技術: [フロントエンド] + Cloudflare Workers + D1 + KV
外部API: [選択したAPI]
制約: テーブル2以内、エンドポイント5以内、認証なし
ヒアリングは3問以内。出力は簡潔に。
```

**注意**: ORMは使わない。生SQLでD1を操作する設計にする（学習目的）。

### Phase 5: DB設計

**feature-trainerにはなかった新しいPhase。**

**ここで教えること：**

```
ここが今回の一番の山場。「テーブル設計」をやる。
feature-trainerにはなかった新しいステップ。

テーブルとは、Excelの表みたいなもの。
- 列（カラム）= 項目名（「タイトル」「著者」「登録日」）
- 行（レコード）= 1件分のデータ

例えば読書記録アプリなら：

books テーブル:
| id | title        | author    | status | created_at |
|----|-------------|-----------|--------|------------|
| 1  | 坊っちゃん    | 夏目漱石   | 読了    | 2024-01-15 |
| 2  | 人間失格     | 太宰治     | 読書中  | 2024-01-20 |

この「枠組み」を最初に決める。
あとからカラムを追加するのは面倒なので、先に設計する。

なぜ実装の前にDB設計をやるか：
料理で言えば「冷蔵庫の棚を整理してから食材を入れる」のと同じ。
棚の大きさや仕切りを決めずに食材を詰め込むと、後で取り出せなくなる。

feature-trainerでは localStorage に JSON で適当に入れていた。
今回はDBに「ちゃんとした形」で保存する。その「形」を先に決める。
```

**【レベル3のみ】**

```
テーブルにuser_idカラムを追加する。これが「誰のデータか」を区別する鍵。

例：
CREATE TABLE books (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  user_id TEXT NOT NULL,  ← これが追加
  title TEXT NOT NULL,
  author TEXT,
  status TEXT DEFAULT '未読',
  created_at TEXT DEFAULT (datetime('now'))
);

全SELECTに WHERE user_id = ? をつける：
SELECT * FROM books WHERE user_id = ?;

全INSERTに user_id を含める：
INSERT INTO books (user_id, title, author) VALUES (?, ?, ?);

これだけ。DBの観点では「カラム1つ追加してWHERE句に入れる」だけ。
認証サービスが返すユーザーIDをそのまま使う。
```

#### 5-1. SQLの基礎（最小限）

```
テーブルを操作するのが SQL（エスキューエル）という言語。
今回覚えるのは4つだけ：

【CREATE TABLE】テーブル（棚）を作る
  → 「こういう項目の棚を用意して」と指示する

【INSERT】データを入れる
  → 「この棚にこのデータを入れて」

【SELECT】データを取り出す
  → 「この棚からこういう条件のデータを出して」

【DELETE】データを消す
  → 「この棚からこのデータを消して」

UPDATE（更新）も使うかもしれないが、基本はこの4つ。
この4つをまとめて CRUD（クラッド）と呼ぶ：
  Create = INSERT
  Read = SELECT
  Update = UPDATE
  Delete = DELETE

AIがSQL文を書くので、「こういう意味か」とわかればOK。
覚えなくていい。
```

#### 5-2. テーブル定義

ARCHITECTURE.md のテーブル設計をもとに、実際のCREATE TABLE文を作成する。

```
これが「マイグレーション」。
テーブルの設計図をSQLで書いて、D1に実行させる。
「この棚をこの形で作ってください」と指示する。

マイグレーションファイルは「棚の組み立て手順書」。
このファイルがあれば、いつでも同じ棚を再現できる。
ローカル（自分のPC）でも本番（インターネット上）でも同じ棚が作れる。
```

**実行**: マイグレーションファイルを作成し、`wrangler d1 execute` でテーブルを作成する。ローカルD1で動作確認する。

#### 5-3. 動作確認

テストデータを INSERT して SELECT で取り出す。ユーザーに見せて「DBが動いている」ことを実感させる。

```
今、D1にデータが入って、取り出せた。
これがデータベースの基本。入れる・出す・消す。

localStorageとの違いは：
- localStorage → そのブラウザだけ。端末が変わると消える
- D1 → サーバー上。どこからアクセスしても同じデータ

もう1つ大事な違い：
- localStorage → 形が自由すぎて、後から「このデータの形おかしくない？」となりやすい
- D1 → テーブル設計で形を先に決めるから、常に整理されたデータが入る

feature-trainerで localStorage を使った時、
「データの形がバラバラになった」経験はない？
DB はそれを防ぐ仕組みでもある。
```

### Phase 6: 実装

**ここで教えること：**

```
設計とDB準備が終わった。ここから実装。
feature-trainerでもやった「実装指示」のフェーズ。

「実装指示」とは、AIに「こういう機能を作って」と自然な日本語で伝えること。
スキル（/xxx）ではなく、普通の文章で指示する。

例：
「ブックリスト画面を作って。D1からデータを取得して一覧表示する。
 追加ボタンを押したら Open Library API で書籍を検索できるようにして。」

AIがこの指示を読んで、自動でタスクに分割して並列に実装する。
ご飯を炊きながら同時におかずも作る。1つずつやるより速い。

ここまでの設計（CORE.md / ARCHITECTURE.md）と DB設計があるから、
AIは正確に作れる。
設計なしにいきなり「作って」と言うと、AIも迷って中途半端なものになる。
だから先に設計を固めた。

feature-trainerと同じ：
あなたの役割 = 「何を作るか指示して、結果を確認する人」
AIの役割 = 「タスクを分割して並列に実装する人」
```

**よくある失敗：**
- 指示が曖昧すぎる → 「どの画面に何を表示するか、具体的に伝えよう」
- 一度に全部作ろうとする → 「まず1画面だけ作って動かそう。動いたら次」
- エラーハンドリングに凝る → 「最低限でいい。try-catchで囲んでエラーメッセージ表示」

**実行**:
1. 実装指示を出して並列実装する

実装時の注意点：
- Workers のエンドポイントは ARCHITECTURE.md の設計通りに
- D1操作は生SQL（ORMなし）
- 外部API呼び出しは Workers 経由（フロントから直接呼ばない）
- KVキャッシュは ARCHITECTURE.md のキャッシュ設計通りに
- APIキーは環境変数（`env.API_KEY_NAME`）から取得。ハードコーディング厳禁
- エラーハンドリングは最低限（try-catch + ユーザーへのメッセージ表示）

**ここで教えること（外部APIをWorkersで呼ぶ理由）：**

```
「なぜフロントエンドから直接APIを呼ばないのか？」

2つの理由がある：

1. APIキーを隠すため
   フロントエンドのコードはブラウザに送られるから、誰でも見れる。
   APIキーをフロントに書くと、全世界に公開されてしまう。
   Workers（裏方）で呼べば、キーはサーバー側に隠せる。

2. CORS（コース）という壁
   ブラウザには「別のサービスに直接データを取りに行ってはいけない」
   というセキュリティルールがある。
   Workers を経由すれば、この壁を回避できる。

つまり Workers は「代理人」。
ユーザー → フロントエンド: 「このデータ欲しい」
フロントエンド → Workers: 「このデータ取ってきて」
Workers → 外部API: 「このデータちょうだい」（APIキー付き）
Workers → フロントエンド: 「はいどうぞ」

この「代理人パターン」は、プロの開発でも定番。
```

### Phase 7: 検証

**ここで教えること：**

```
実装が終わったら検証。
feature-trainerでもやった /verify スキル。

/verify は「作ったものがちゃんとできているか確認する」スキル。

料理で言えば「味見」と「盛り付け確認」。
作りっぱなしで出すと、塩が足りなかったり皿からはみ出てたりする。

3種類のチェックがある：
- テスト: 「ボタンを押したら正しく動くか」を自動で確認するプログラムを作って実行
- 静的検証: コードの品質チェック。「動くけど問題あるコード」を見つける。文章の校正に近い
- 動的検証: 実際にブラウザで画面を開いて、見た目や操作感を確認

選択画面が出るので、チェックしたいものを選ぶ。
よくわからなければ全部選んでOK。

前回と違うのは、今回チェックする範囲が広いこと：
- フロントエンドの表示は正しいか（前回と同じ）
- Workers のエンドポイントは正しく動くか（新しい）
- D1 にデータが正しく保存されているか（新しい）
- 外部APIからデータが取れているか（新しい）
- KV キャッシュが効いているか（新しい）

「動く」と「正しい」は違う。
画面が表示されていても、DBに変なデータが入っているかもしれない。
だから複数の観点でチェックする。
```

**よくある失敗：**
- 検証を飛ばしたがる → 「動くと正しいは違う。DBのデータは見た目じゃわからない」
- エラーが出てパニック → 「エラーは普通。AIが直す。内容を教えて」


### Phase 8: デプロイ

**ここで教えること：**

```
検証を通過したらデプロイ。インターネットに公開する。
feature-trainerでもやった /deploy スキル。

/deploy は裏でやっていることは3つ：
1. add: 「この変更を送りたい」とマークする（荷物を段ボールに詰める）
2. commit: 「この変更をまとめて記録する」（段ボールにラベルを貼る）
3. push: GitHubに送る（宅配便で発送）

feature-trainerと同じ。push するだけ。

Phase 2 で GitHub Actions を設定済みだから、
push したら自動で Workers + D1 + KV が全部デプロイされる。
手動で何かする必要はない。

前回と同じ体験：push → 自動デプロイ → URL で確認。
でも今回は「フロントだけ」じゃなく「フルスタック」が自動でデプロイされる。
```

**実行**:
1. /deploy で GitHub push
2. GitHub Actions タブで自動デプロイの進行を確認（緑のチェックがつくまで待つ）
3. 本番URLで動作確認

**デプロイ後の確認ポイント：**
- フロントエンドが表示されるか
- Workers経由でD1のデータが取得できるか
- 外部APIからデータが取れるか
- KVキャッシュが効いているか（2回目のアクセスが速いか）

**ここで教えること：**

```
Phase 2 で GitHub Actions を先に設定しておいた意味がここで効く。

push しただけで全部デプロイされた。
フロントもバックエンドもDBも、全部自動。

これが CI/CD の力。
「push = デプロイ」のパイプラインを最初に作っておけば、
あとは機能を作ることだけに集中できる。

本番の開発でも同じ。環境構築と自動デプロイは最初にやる。

feature-trainerで学んだ「環境構築は先にやる」。
同じ原則がフルスタックでも効いた。
型は変わらない。
```

**デプロイ後、実際のURLをブラウザで開いて一緒に確認する。**

```
これがあなたが作ったフルスタックWebアプリ。

前回（feature-trainer）は「フロントだけ」だった。
今回は：
- ブラウザで画面が見える（フロントエンド）
- 裏でWorkersが動いている（バックエンド）
- データがD1に保存されている（データベース）
- 外部APIからデータを取ってきている（API連携）
- よく使うデータはKVにメモされている（キャッシュ）

全部が連携して動いている。しかもpush一発でデプロイされた。
スマホからも見れる。友達に送ることもできる。
```

### Phase 9: 振り返り

```
完了！フルスタックのプロダクトを、同じフレームワークの型で作り上げた。

■ 今回の流れ（feature-trainerとの対比）
0. 前提確認 ← 前回はオリエンテーション
1. テーマ選択 ← 同じ型
2. 環境構築 ← Workers + D1 + KV + GitHub Actions が追加
3. スコープ固定 ← 同じ型（DB/APIの制約が追加）
4. /draft ← 「何を作るか」＋「どう作るか」を一気通貫で設計
5. DB設計 ← 新しいPhase（テーブルの枠組みを決める）
6. 実装指示 → 並列実装 ← 同じ型（自然言語で指示）
7. /verify ← 同じ型（DBとAPIの検証が追加）
8. /deploy ← push だけ（GitHub Actions で自動デプロイ）
9. 振り返り ← 今ここ

■ 気づいてほしいこと
- 型は変わらなかった。Why → How → What → Code の流れは同じ
- 道具が増えても、やることの順番は同じ
- 新しいのは「DB設計」だけ。それ以外は拡張しただけ
- /draft は技術が変わっても同じ。「誰の何を解決するか」は普遍
- /verify も同じスキルで、チェック範囲が広がっただけ
- /deploy も同じ。push するだけ。CI/CD が裏で頑張ってくれる

■ 今回使ったスキル（振り返り）
- /draft: 「何を作るか」＋「どう作るか」を決めた → docs/CORE.md, docs/ARCHITECTURE.md
- /verify: 「ちゃんと動くか」を確認した（テスト・静的・動的の3種類）
- /deploy: インターネットに公開した（add → commit → push）

覚えてほしいのは「スキルの名前」じゃなく「何のためにやったか」。
- 設計してから作る（/draft）
- 環境を先に整える（Phase 2）
- 作ったら確認する（/verify）
- 確認してから公開する（/deploy）
この順番は、どんなプロダクトでも同じ。

■ 今回学んだ技術（振り返り）
- データベース（D1）→ サーバー上のデータ倉庫。どこからでもアクセス可
- SQL → DBを操作する言語。CRUD（Create, Read, Update, Delete）
- テーブル → Excelの表みたいなもの。カラム（列）とレコード（行）
- マイグレーション → テーブルの設計図をSQLで書いて実行すること
- 外部API → 他のサービスからデータをもらう仕組み。電話のイメージ
- APIキー → APIを使うための身分証明書。秘密にする
- Workers → サーバーレス関数。裏方の作業員。厨房
- エンドポイント → Workers が受け付ける窓口。注文カウンター
- KV → 付箋ボード。APIの結果をメモして高速化（キャッシュ）
- 環境変数 → 秘密の設定値。コードに直接書かない
- GitHub Actions → 自動配送業者。push したら自動でデプロイ
- CI/CD → 継続的デプロイ。手動デプロイを排除する仕組み
- Secrets → GitHub の金庫。APIトークンなど秘密の値を安全に保管
- wrangler → Cloudflare の道具箱。Workers/D1/KVを管理するツール
- wrangler.toml → 接続設定ファイル。住所録
- CORS → ブラウザのセキュリティルール。Workers で回避できる

【レベル3のみ】
- 認証 → 「この人は誰か」を確認する仕組み
- 外部認証サービス（Clerk）→ ログイン機能の外注先。自前で作らない
- PUBLISHABLE_KEY → 看板の鍵（見えてもいい）
- SECRET_KEY → 裏口の鍵（絶対に見せない）
- user_id → DBのレコードに「持ち主」をつけるカラム
- WHERE user_id = ? → 「自分のデータだけ取り出す」クエリ
- マルチテナント → 1つのアプリを複数ユーザーが使う設計。user_idで分離

これらも「覚えなきゃ」と思わなくていい。
2回目、3回目とやるうちに自然と身につく。

■ feature-trainer → fullstack-trainer で何が変わったか
| 項目 | feature-trainer | fullstack-trainer |
|------|----------------|-------------------|
| データ保存 | localStorage（ブラウザ内） | D1（サーバー上） |
| 外部連携 | なし | 外部API 1つ |
| バックエンド | なし | Workers |
| キャッシュ | なし | KV |
| デプロイ方法 | Cloudflare Pages自動 | GitHub Actions自動 |
| 設計の型 | CORE → ARCH | CORE → ARCH（同じ！） |
| 実装の型 | 実装指示 → 並列実装 | 実装指示 → 並列実装（同じ！） |
| 検証の型 | /verify | /verify（同じ！） |
| 公開の型 | /deploy | /deploy（同じ！） |

→ 変わったのは「道具」だけ。「型」は全く同じ。

■ 次にやること
- 別のテーマで /fullstack-trainer をもう1回やる（レベルを上げて）
- 慣れたら /solo-trainer で自分でスキルを使って開発を回す練習
- /draft から自分のフルスタックプロダクトを作ってみるのもいい
- feature-trainerで作ったプロダクトにDB + APIを足してみるのもいい
```

---

## つまずいた時のガイド（全Phase共通）

各Phaseで以下のメッセージを適宜挟む：

```
わからないこと・動かないことがあったら、遠慮なく言って。
エラー画面のスクリーンショットや、何をやって何が起きたかを教えてくれれば対処できる。
「何がわからないかわからない」でもOK。状況を一緒に見る。
```

### エラーが出た時の対応フロー

```
エラーが出た！→ 慌てなくて大丈夫。

1. エラーメッセージを読む（AIが読んで訳してくれる）
2. 原因を特定する（AIが調べる）
3. 修正する（AIが直す）

あなたがやることは「エラーが出た」と教えてくれること。それだけ。
```

### よくあるエラーパターン

| エラー | 原因 | 対処 |
|--------|------|------|
| 「D1 database not found」 | wrangler.toml の設定ミス | AIが設定を修正する |
| 「KV namespace not found」 | KV のバインディング設定漏れ | AIが設定を修正する |
| 「CORS error」 | フロントからAPIを直接呼んでいる | Workers 経由に修正する |
| 「API key invalid」 | APIキーの設定ミス or 期限切れ | 環境変数を確認する |
| 「GitHub Actions failed」 | Secrets 未設定 or deploy.yml のミス | AIが修正する |
| 「wrangler command not found」 | wrangler 未インストール | AIがインストールする |

---

## 既存スキルとの連携

- /draft を実際に呼び出す
- 呼び出し時に「fullstack-trainerモード」の制約情報をコンテキストに含める
- 各スキルのヒアリングは通常より簡潔にする指示を渡す（3問以内目安）
- 出力フォーマットは既存スキルのものをそのまま使う
- /draft では Workers + D1 + KV の構成を含める指示を追加する
- **/verify, /deploy を呼び出す前に、そのスキルが何をするかを毎回説明する**

## このスキルの本質

このスキルの価値は「フルスタック技術を覚える」ことではなく、「型はスケールする」と実感すること。

feature-trainerで学んだ型（CORE → ARCH → 実装 → 検証 → デプロイ）は、フロントエンドだけでなくフルスタック開発でもそのまま使える。道具が増えても、思考の順番は変わらない。

成果物のプロダクト自体は小さい。でも：
- なぜ DB 設計を ARCH の後・実装の前にやるのか
- なぜ外部APIを Workers 経由で呼ぶのか（フロントから直接呼ばない理由）
- なぜ APIキーを環境変数にするのか
- なぜ KV でキャッシュするのか
- D1 と localStorage はどう使い分けるのか
- なぜ認証を自前で作らないのか（セキュリティリスクと開発コスト）
- なぜ user_id を全テーブルに入れるのか（マルチテナントの基本）
- 「WHERE user_id = ?」が全ての起点であること
- /draft, /verify, /deploy は技術が変わっても同じスキルで対応できること

これが身体で理解できていれば、本番のフルスタック開発でも同じ型が使える。
